{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xU849iXGJJyI",
        "outputId": "31feadca-86e1-4a42-affd-536360d89d67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.9837416481069042\n"
          ]
        }
      ],
      "source": [
        "# Fake News Detection using TF-IDFand Logistic Regression\n",
        "\n",
        "# =========================================\n",
        "# 1. IMPORT REQUIRED LIBRARIES\n",
        "# =========================================\n",
        "\n",
        "# pandas is used to read and handle CSV data\n",
        "import pandas as pd\n",
        "\n",
        "# train_test_split is used to split data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# TF-IDF converts text into numerical features\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Logistic Regression is the classification model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# accuracy_score is used to evaluate model performance\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# =========================================\n",
        "# 2. LOAD DATASET\n",
        "# =========================================\n",
        "\n",
        "# Load fake news dataset\n",
        "fake = pd.read_csv(\"Fake.csv\")\n",
        "\n",
        "# Load real news dataset\n",
        "true = pd.read_csv(\"True.csv\")\n",
        "\n",
        "\n",
        "# =========================================\n",
        "# 3. ADD LABELS\n",
        "# =========================================\n",
        "\n",
        "# Label fake news as 0\n",
        "fake[\"label\"] = 0\n",
        "\n",
        "# Label real news as 1\n",
        "true[\"label\"] = 1\n",
        "\n",
        "\n",
        "# =========================================\n",
        "# 4. COMBINE DATASETS\n",
        "# =========================================\n",
        "\n",
        "# Combine fake and real news into a single dataset\n",
        "data = pd.concat([fake, true])\n",
        "\n",
        "# Shuffle the data so fake and real news are mixed\n",
        "data = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "\n",
        "# =========================================\n",
        "# 5. SPLIT INPUTS AND OUTPUTS\n",
        "# =========================================\n",
        "\n",
        "# X contains the news text (input feature)\n",
        "X = data[\"text\"]\n",
        "\n",
        "# y contains the labels (0 = fake, 1 = real)\n",
        "y = data[\"label\"]\n",
        "\n",
        "\n",
        "# =========================================\n",
        "# 6. TRAIN-TEST SPLIT\n",
        "# =========================================\n",
        "\n",
        "# Split data into training (80%) and testing (20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,        # 20% data for testing\n",
        "    random_state=42       # ensures same split every time\n",
        ")\n",
        "\n",
        "\n",
        "# =========================================\n",
        "# 7. TF-IDF VECTORIZATION\n",
        "# =========================================\n",
        "\n",
        "# Create TF-IDF vectorizer\n",
        "# stop_words=\"english\" removes common words like 'the', 'is', 'and'\n",
        "tfidf = TfidfVectorizer(stop_words=\"english\")\n",
        "\n",
        "# Learn vocabulary and transform training text into vectors\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "\n",
        "# Transform test text using the same vocabulary\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "\n",
        "# =========================================\n",
        "# 8. TRAIN LOGISTIC REGRESSION MODEL\n",
        "# =========================================\n",
        "\n",
        "# Create Logistic Regression model\n",
        "# max_iter increased to ensure convergence\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Train the model using TF-IDF features\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "\n",
        "# =========================================\n",
        "# 9. MAKE PREDICTIONS\n",
        "# =========================================\n",
        "\n",
        "# Predict labels for test data\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "\n",
        "# =========================================\n",
        "# 10. EVALUATE MODEL\n",
        "# =========================================\n",
        "\n",
        "# Calculate accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy\n",
        "print(\"Model Accuracy:\", accuracy)\n"
      ]
    }
  ]
}